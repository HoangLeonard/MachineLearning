{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "*thuật toán giảm gradient để tối ưu một hàm khả vi*\n",
    "\n",
    "Problem minimize objective function:\n",
    "$J_{θ} → min$ \n",
    "$$\n",
    "    θ^{t+1} = θ^{t} - α∇J(θ^{t})\n",
    "$$\n",
    "the effection of algo depends on the α. (usually-used $α: 10^{-3}, 10^{-2}$)\n",
    "\n",
    "$$ lim _{t→inf}θ = \\theta^* $$\n",
    "\n",
    "if we dont have a convex function. gradient descent can find a lobal minimum but that is not good, we need a global minimum. We can try more times, with new initial theta, then selecting the minimum one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Gradient Descent for linear regression\n",
    "\n",
    "$$\n",
    "\\theta ^{t+1} = θ^t - \\frac{α}{N}X^T(Xθ^{t}-y)\n",
    "    \n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
